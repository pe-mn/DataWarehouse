import configparser


# CONFIG
config = configparser.ConfigParser()
config.read('dwh.cfg')

ARN                    = config.get('IAM_ROLE','ARN')
LOG_JSONPATH           = config.get('S3','LOG_JSONPATH')
LOG_DATA               = config.get('S3','LOG_DATA')
SONG_DATA              = config.get('S3','SONG_DATA')

# DROP TABLES

staging_events_table_drop = "DROP TABLE IF EXISTS stagingEvents"
staging_songs_table_drop = "DROP TABLE IF EXISTS stagingSongs"

songplay_table_drop = "DROP TABLE IF EXISTS factSongplay"
user_table_drop = "DROP TABLE IF EXISTS dimUser"
song_table_drop = "DROP TABLE IF EXISTS dimSong"
artist_table_drop = "DROP TABLE IF EXISTS dimArtist"
time_table_drop = "DROP TABLE IF EXISTS dimTime"


# an example of what a single song file, TRAABJL12903CDCF1A.json, looks like
# {"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}

# Log Dataset (EVENTS DATA)
# -------------------------
# The second dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate app activity logs from an imaginary music streaming app based on configuration settings.
# The log files in the dataset you'll be working with are partitioned by year and month. For example, here are file paths to two files in this dataset.

# an example of what the data in a log file, 2018-11-12-events.json, looks like.
# artist (contains None), auth, firstName, gender, itemInSession, lastName, length (contains NaN), level, location, method, page, registration, sessionId, song (contains None), status, ts, userAgent, userId

# Note
# The SERIAL command in Postgres is not supported in Redshift. The equivalent in redshift is IDENTITY(0,1), which you can read more on in the Redshift Create Table Docs.

# -------------------------------------------------------------------------------------------------------------------------------

# CREATE TABLES
# Amazon Redshift defaults the sort key and distribution style to AUTO
# https://knowledge.udacity.com/questions/779023
# https://knowledge.udacity.com/questions/707168
# https://knowledge.udacity.com/questions/394360
# https://knowledge.udacity.com/questions/47434

# :warning: In the staging_events table, The registration field's data type is incorrect. It should be VARCHAR instead. Looking at the sample image, they are (as far as we can tell from the screenshot) 12-digit registration codes, and we are not supposed to perform any numerical operations on them:

staging_events_table_create= ("""
CREATE TABLE IF NOT EXISTS stagingEvents ( 
    artist            varchar, 
    auth              varchar, 
    firstName         varchar, 
    gender            char, 
    itemInSession     int, 
    lastName          varchar, 
    length            float, 
    level             varchar, 
    location          varchar, 
    method            varchar, 
    page              varchar, 
    registration      varchar, 
    sessionId         int, 
    song              varchar, 
    status            int, 
    ts                bigint, 
    userAgent         varchar, 
    userId            int)
""")


staging_songs_table_create = ("""
CREATE TABLE IF NOT EXISTS stagingSongs ( 
    num_songs         int,
    artist_id         varchar,
    artist_latitude   double precision, 
    artist_longitude  double precision, 
    artist_location   varchar, 
    artist_name       varchar, 
    song_id           varchar, 
    title             varchar,
    duration          numeric, 
    year              int)
""")


# -------------------------------------------------------------------------------------------------------------------------------


# PRIMARY KEY constraints need to be set for all index fields in your dimension and fact tables.

# Please include NOT NULL constraints where appropriate.
# A song should have a title, an artist should have a name, a user should have a first name, etc.

# According to the documentation from Redshift, the PRIMARY KEY, FOREIGN KEY, and NOT NULL constraints are informational only. Despite that, it is still a best practice to include them in your tables.
        

# â€¢	songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent
songplay_table_create = ("""
CREATE TABLE IF NOT EXISTS factSongplay(
    songplay_id       int               IDENTITY(0,1)   PRIMARY KEY, 
    start_time        timestamp         NOT NULL        sortkey, 
    user_id           int               NOT NULL, 
    level             text, 
    song_id           varchar           NOT NULL, 
    artist_id         varchar           NOT NULL, 
    session_id        int               NOT NULL, 
    location          varchar,
    user_agent        varchar)
    diststyle auto;
""") 

# user_id, first_name, last_name, gender, level
user_table_create = ("""
CREATE TABLE IF NOT EXISTS dimUser(
    user_id           int               sortkey         PRIMARY KEY,
    first_name        varchar           NOT NULL,
    last_name         varchar,
    gender            char,
    level             text)
    diststyle auto;
""")

song_table_create = ("""
    CREATE TABLE IF NOT EXISTS dimSong(
    song_id           varchar                           PRIMARY KEY, 
    title             varchar           NOT NULL, 
    artist_id         varchar, 
    year              int               sortkey,               
    duration          numeric)
    diststyle auto;
""")

# https://stackoverflow.com/questions/8150721/which-data-type-for-latitude-and-longitude
artist_table_create = ("""
CREATE TABLE IF NOT EXISTS dimArtist(
    artist_id         varchar                            PRIMARY KEY,
    name              varchar            NOT NULL, 
    location          varchar, 
    latitude          double precision, 
    longitude         double precision)
    diststyle auto;
""")

time_table_create = ("""
CREATE TABLE IF NOT EXISTS dimTime(
    start_time        timestamp          sortkey         PRIMARY KEY, 
    hour              int                NOT NULL, 
    day               int                NOT NULL, 
    week              int                NOT NULL, 
    month             int                NOT NULL, 
    year              int                NOT NULL, 
    weekday           int                NOT NULL) 
    diststyle auto;
""")


# -------------------------------------------------------------------------------------------------------------------------------


# STAGING TABLES

# config["S3"]["LOG_JSONPATH"] setting needs to be used for the JSON parameter when running the COPY query for staging_events. Failing to do this would lead to empty data for many fields. 
# On the contrary, for the staging_songs table, you should use the "JSON auto" setting.
        
# https://knowledge.udacity.com/questions/137878
# https://knowledge.udacity.com/questions/39352
# https://www.bmc.com/blogs/amazon-redshift-copy-json-data/

staging_events_copy = (f"""
    copy stagingEvents from {LOG_DATA}
    iam_role '{ARN}'
    json {LOG_JSONPATH}
    TIMEFORMAT 'epochmillisecs'  
    region 'us-west-2';   
""")

#     COMPUPDATE OFF  


staging_songs_copy = (f"""
    copy stagingSongs from {SONG_DATA}
    credentials 'aws_iam_role={ARN}'
    json 'auto'
    region 'us-west-2';
""")


# -------------------------------------------------------------------------------------------------------------------------------


# FINAL TABLES

songplay_table_insert = ("""
    INSERT INTO factSongplay (start_time, user_id, level, song_id, artist_id, session_id, location, user_agent) 
    SELECT DISTINCT TIMESTAMP 'epoch' + ts/1000 * INTERVAL '1 second' AS start_time,
                    userId,
                    level,
                    song_id,
                    artist_id,
                    sessionId,
                    location,
                    userAgent                    
    From stagingSongs S LEFT Join stagingEvents E
        ON  S.title = E.song
        AND S.artist_name = E.artist
    WHERE E.page='NextSong' 
""")

#     WHERE s.song_id IS NOT NULL
#     OR s.artist_id IS NOT NULL


# After adding PRIMARY KEY in all the tables, you will run into duplicate key conflicts, 
# for this you will have to handle these conflicts.

# For the user table insert query, the conflict resolution is a little different.
# A user will be present even if he/she is a free tier user. 
# But what if the free tier user converts into a paid user. 
# In that case we have to modify the level of the user as below:
# ON CONFLICT(user_id) DO UPDATE SET level = excluded.level

# https://knowledge.udacity.com/questions/276119

user_table_insert = ("""
    INSERT INTO dimUser (user_id, first_name, last_name, gender, level)
    SELECT DISTINCT userId,
                    firstName,
                    lastName,
                    gender,
                    level
    FROM stagingEvents
    WHERE page = 'NextSong' 
    AND userId IS NOT NULL
""")

song_table_insert = ("""
    INSERT INTO dimSong (song_id, title, artist_id, year, duration)
    SELECT DISTINCT song_id,
                    title,
                    artist_id,
                    year,
                    duration
    FROM stagingSongs  
    WHERE song_id IS NOT NULL
    
""")

artist_table_insert = ("""
    INSERT INTO dimArtist (artist_id, name, location, latitude, longitude)
    SELECT DISTINCT artist_id,
                    artist_name,
                    artist_location,
                    artist_latitude,
                    artist_longitude
    FROM stagingSongs
    WHERE artist_id IS NOT NULL
""")

# IMPORTANT !!!
# https://knowledge.udacity.com/questions/610513
time_table_insert = ("""
    INSERT INTO dimTime (start_time, hour, day, week, month, year, weekday)
    SELECT  TIMESTAMP 'epoch' + ts/1000 * INTERVAL '1 second' AS start_time,
            EXTRACT (HOUR    FROM start_time), 
            EXTRACT (DAY     FROM start_time),
            EXTRACT (WEEK    FROM start_time), 
            EXTRACT (MONTH   FROM start_time),
            EXTRACT (YEAR    FROM start_time), 
            EXTRACT (WEEKDAY FROM start_time) 
    FROM stagingEvents
    WHERE ts IS NOT NULL
""")


# -------------------------------------------------------------------------------------------------------------------------------




# QUERY LISTS

create_table_queries = [staging_events_table_create, staging_songs_table_create, songplay_table_create, user_table_create, song_table_create, artist_table_create, time_table_create]
drop_table_queries = [staging_events_table_drop, staging_songs_table_drop, songplay_table_drop, user_table_drop, song_table_drop, artist_table_drop, time_table_drop]
copy_table_queries = [staging_events_copy, staging_songs_copy]
insert_table_queries = [songplay_table_insert, user_table_insert, song_table_insert, artist_table_insert, time_table_insert]


